文件折叠其实不是一个好的选择。因为很多时候可能是在一个阶段性任务完成后才压缩，这一情况下本身上下文只要保持概要即可。可以考虑改为仅保留类名、接口名，函数签名及类/接口的具体内容也一起忽略。此外，可以考虑设定一个token数阈值(例如10000 tokens)，高于阈值时按照超出的比例随机丢弃(仍超出阈值则再按照固定数量随机丢弃)

此外，作为回退方案的滑动窗口也不是一个好的选择。因为一般情况下中间的段落才是模型本身注意力最低下的，删除消息也应该优先从中间开始删除。可以考虑计算token的1/6、5/6位数，把这一段随机丢弃，具体逻辑类似文件折叠

考虑该如何设计


鉴于我需要作出的优化，需要把文件折叠作为独立的部分。此外，需要以tiktoken作为压缩结果计算的唯一来源，因为文件折叠不能从api处获取token大小的响应
此外，由于不同模型的分词器不同，对于压缩前后的token大小需要完全使用tiktoken计算，以避免切换模型后压缩后大小反而更小，导致压缩结果直接被拒绝。1/6、5/6位数的计算也由tiktoken确定。只需要找到消息索引即可，分界点不需要精确到字符

关于文件折叠，你对随机丢弃的理解有问题：
比例 = (文件折叠后占用token大小/阈值) -1【不得<0，<0意味着根本不需要随机丢弃】，而非人为决定的。
固定批大小是为了满足token阈值而设置的。即按比例丢弃后仍然不能满足要求，则按照批大小随机采样并丢弃，执行多次，直到文件折叠大小满足需求。我最终决定放弃，改为通过启发式方法来确定批大小，例如假定每个类名+行样板的token占用，直接完成批大小的计算，保证1次完成后处理，避免多次对象操作开销、tiktoken计算开销[即使不符合要求也可以不管])

此外，还可以考虑一个优化，在丢弃结束后合并函数块：类、接口始终单独给出行数。函数名则直接一次性合并多个，只有在出现类、接口，或连续行数超过100行时才中断。
这样能减少行跨度样板占用的token。

另外，关于回退方案，
可以改为这样：删除中间1/6-5/6上下文中所有的工具调用和除文件查看外的工具调用返回。
对于文件查看结果【包括不在中间部分的】：同样对所有文件执行折叠。
完成后[包括前面提到的所有后处理]再计算是否超出阈值(单独定义，与之前的不一样。可以考虑用上全局默认值50000 tokens[其他地方大概已经没用])。若超出阈值，再从中间消息开始删除消息(不再随机丢弃，以免消息不匹配导致llm工具调用出问题)[同样可以考虑启发式批大小，一次结束]。